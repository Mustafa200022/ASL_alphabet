# -*- coding: utf-8 -*-
"""ASL alphabet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dlD35lcNyt1zQ-ibJlh9woyHvHv-o0V6

# Downloading & Unzipping dataset
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install -q kaggle

from google.colab import files

files.upload()

!mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!mkdir dataset

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/dataset

!kaggle datasets download -d grassknoted/asl-alphabet

!unzip -x /content/dataset/asl-alphabet.zip

"""# Explore the dataset"""

import os
for folder in os.listdir('/content/dataset/asl_alphabet_train/asl_alphabet_train'):
  images = [x for x in os.listdir(f'/content/dataset/asl_alphabet_train/asl_alphabet_train/{folder}') if (x.endswith('.jpg') or x.endswith('.jpeg'))]
  print(f'{folder} : {len(images)} images')

import cv2 as cv
from google.colab.patches import cv2_imshow

img = cv.imread('/content/dataset/asl_alphabet_train/asl_alphabet_train/A/A1018.jpg')
cv2_imshow(img)

img.shape

"""# Data Generator"""

CLASSES_labels = {}
for index, folder in enumerate(os.listdir('/content/dataset/asl_alphabet_train/asl_alphabet_train')):
  CLASSES_labels[folder] = index

CLASSES_labels

files = os.listdir("/content/dataset/asl_alphabet_train/asl_alphabet_train")
images_path = []
images_labels = []

for file_ in files:
  paths = [path for path in os.listdir(f'/content/dataset/asl_alphabet_train/asl_alphabet_train/{file_}') if (path.endswith('.jpg') or path.endswith('.jpeg'))]
  for path in paths:
    images_path.append(f'/content/dataset/asl_alphabet_train/asl_alphabet_train/{file_}/{path}')
    images_labels.append(CLASSES_labels[f'{file_}'])

len(images_path), len(images_labels)

from sklearn.model_selection import train_test_split

images_paths_train, images_paths_validation, images_labels_train, images_labels_validation = train_test_split(images_path, images_labels, test_size=0.1, stratify=images_labels, random_state=42)

images_paths_test = []
images_labels_test = []
test_file = os.listdir('/content/dataset/asl_alphabet_test/asl_alphabet_test')

for image in test_file:
  images_paths_test.append(f'/content/dataset/asl_alphabet_test/asl_alphabet_test/{image}')
  label = image.split('_')[0]
  images_labels_test.append(CLASSES_labels[f'{label}'])

len(images_paths_test), len(images_labels_test)

images_paths_test , images_labels_test

import tensorflow.keras as keras
import numpy as np
import imgaug.augmenters as iaa
from tensorflow.keras.applications.resnet50 import preprocess_input

!pip install git+https://github.com/aleju/imgaug.git

class DataGenerator(keras.utils.Sequence):
  'Generates data for Keras'
  def __init__(self, list_IDs, labels, batch_size=16, dim=(200,200), n_channels=3,
              n_classes=29, shuffle=True, augmentation=True):
    'Initialization'
    self.dim = dim
    self.batch_size = batch_size
    self.labels = labels                         
    self.list_IDs = list_IDs
    self.n_channels = n_channels
    self.n_classes = n_classes
    self.shuffle = shuffle
    self.augmentation = augmentation
    if self.augmentation:
      self.aug = iaa.Sequential([
        iaa.Affine(rotate=(-25, 25)),
        iaa.AdditiveGaussianNoise(scale=(10, 40)),
        iaa.Affine(shear=15),
        ], random_order=True)
    self.on_epoch_end()

  def __len__(self):
    'Denotes the number of steps per epoch'
    return int(np.floor(len(self.list_IDs) / self.batch_size))

  def __getitem__(self, index):
    'Generate one batch of data'
    # Generate indexes of the batch
    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

    # Find list of IDs
    list_IDs_temp = [self.list_IDs[k] for k in indexes]
    list_labels_temp = [self.labels[k] for k in indexes]

    # Generate data
    X, y = self.__data_generation(list_IDs_temp, list_labels_temp)

    return X, y

  def on_epoch_end(self):
    'Updates indexes after each epoch'
    self.indexes = np.arange(len(self.list_IDs))
    if self.shuffle == True:
        np.random.shuffle(self.indexes)

  def __data_generation(self, list_IDs_temp, list_labels_temp):
    'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
    # Initialization
    X = np.empty((self.batch_size, *self.dim, self.n_channels))
    y = np.empty((self.batch_size), dtype=int)

    # Generate data
    for i, ID in enumerate(list_IDs_temp):
        # Store sample
        img = cv.imread(ID)
        img_resized = cv.resize(img, self.dim[::-1])
        if self.augmentation:   
          img_resized = self.aug(image=img_resized)
        img_resized = img_resized[:,:,::-1] # BGR to RGB
        img_resized = preprocess_input(img_resized)              
        X[i,] = img_resized

        # Store class
        y[i] = list_labels_temp[i]

    return X, keras.utils.to_categorical(y, num_classes=self.n_classes)

train_generator = DataGenerator(list_IDs= images_paths_train, labels= images_labels_train, batch_size=32)
validation_generator = DataGenerator(list_IDs= images_paths_validation, labels= images_labels_validation, shuffle=False, augmentation=False)
test_generator = DataGenerator(list_IDs= images_paths_test, labels= images_labels_test, shuffle=False, augmentation=False)

for images, labels in train_generator:
  print(images.shape)
  print(labels.shape)
  for index in range(len(labels)):
    cv2_imshow(images[index])
    print(labels[index])
  break

"""# Model"""

import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization, Dropout, Dense, Conv2D, MaxPooling2D, Flatten, Input
from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import ModelCheckpoint

model = tf.keras.Sequential()

model.add(keras.layers.Conv2D(64, (3,3), activation="relu", padding="same", input_shape=(200,200,3)))
model.add(keras.layers.Conv2D(64, (3,3), activation="relu", padding="same"))
model.add(keras.layers.MaxPooling2D(3,3))

model.add(keras.layers.Conv2D(128, (3,3), activation="relu", padding="same"))
model.add(keras.layers.Conv2D(128, (3,3), activation="relu", padding="same"))
model.add(keras.layers.MaxPooling2D(3,3))

model.add(keras.layers.Conv2D(256, (3,3), activation="relu", padding="same"))
model.add(keras.layers.Conv2D(256, (3,3), activation="relu", padding="same"))
model.add(keras.layers.MaxPooling2D(3,3))

model.add(keras.layers.Conv2D(512, (3,3), activation="relu", padding="same"))
model.add(keras.layers.Conv2D(512, (3,3), activation="relu", padding="same"))

model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(Dense(29, activation='softmax'))

model.summary()

model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('checkpoint.h5', monitor='val_accuracy', save_best_only=True)

model.fit(x = train_generator,
          validation_data = validation_generator,
          epochs=10,
          callbacks=[model_checkpoint_callback])

